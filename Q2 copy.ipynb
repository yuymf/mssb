{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2 SVM&LDA**\n",
    "\n",
    "*采用支持向量机对男女生样本数据中的（身高、体重、50m 成绩、肺活量）共 4 个特征进行分类；  \n",
    "实现 LDA 算法对前述4个特征进行分类，计算模型预测性能（包含 SE、SP、ACC 和 AUC），   \n",
    "试分析 LDA 算法如果作为降维技术对于各性能指标的影响。*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1.导入模块`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import svm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.处理数据`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 163.    51.     7.5 2500. ]\n",
      " [ 171.    64.     7.5 3500. ]\n",
      " [ 182.    68.     7.8 4900. ]\n",
      " ...\n",
      " [ 170.    60.     7.5 4300. ]\n",
      " [ 168.    55.     6.9 4300. ]\n",
      " [ 168.    50.     7.2 3500. ]]\n",
      "[1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1\n",
      " 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1\n",
      " 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 1 1 1 1 0 1 1 1 1 0 0 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 1 1 1\n",
      " 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "def pre_data(file_path):\n",
    "    data = pd.read_excel(file_path)\n",
    "    data.dropna(axis=0, how='any', subset=['肺活量'], inplace=True) \n",
    "    feature_names = ['身高', '体重', '50米成绩', '肺活量']\n",
    "    data_feature = data[feature_names].values  # 男女三个特征数据的集合\n",
    "    data_label = data['性别男1女0'].values\n",
    "    return data_feature, data_label\n",
    "\n",
    "data_feature, data_label = pre_data(os.path.join('data', '作业数据_2021合成.xls'))\n",
    "print(data_feature)\n",
    "print(data_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.数据分层` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280 70 280 70\n"
     ]
    }
   ],
   "source": [
    "def split_data(data_feature, data_label):\n",
    "\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    for train_index, test_index in split.split(data_feature, data_label):\n",
    "        data_train, data_test = data_feature[train_index], data_feature[test_index]\n",
    "        label_train, label_test = data_label[train_index], data_label[test_index]\n",
    "    return data_train, data_test, label_train, label_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = split_data(data_feature, data_label)\n",
    "print(len(x_train), len(x_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.初始化`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self):\n",
    "    self.se_svm = []\n",
    "    self.sp_svm = []\n",
    "    self.acc_svm = []\n",
    "    self.auc_svm = []\n",
    "    self.se_lda = []\n",
    "    self.sp_lda = []\n",
    "    self.acc_lda = []\n",
    "    self.auc_lda = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.评估函数`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(y_pred,y_true,label=1):\n",
    "    confusion_matrix=metrics.confusion_matrix(y_true,y_pred)\n",
    "    FP = confusion_matrix .sum(axis=0) - np.diag(confusion_matrix )\n",
    "    FN = confusion_matrix .sum(axis=1) - np.diag(confusion_matrix )\n",
    "    TP = np.diag(confusion_matrix )\n",
    "    TN = confusion_matrix .sum() - (FP + FN + TP)\n",
    "    FP = FP.astype(float)\n",
    "    FN = FN.astype(float)\n",
    "    TP = TP.astype(float)\n",
    "    TN = TN.astype(float)\n",
    "    SE = TP/(TP+FN)   # Sensitivity/ hit rate/ recall/ true positive rate\n",
    "    SP = TN/(TN+FP)   # Specificity/ true negative rate  SP\n",
    "    ACC_all=(TP+TN)/(FP+FN+TP+TN)\n",
    "    return SE[label],SP[label],ACC_all[label],roc_auc_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5.SVM分类`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mySVM(self,n):\n",
    "\n",
    "    svm = svm.SVC()\n",
    "    svm.fit(x_train, y_train)\n",
    "    svm_pred=svm.predict(x_test)\n",
    "    se,sp,acc,auc = eval(svm_pred,y_test)\n",
    "    self.se_svm.append(se);self.sp_svm.append(sp);self.acc_svm.append(acc);self.auc_svm.append(auc)\n",
    "    return self.se_svm, self.sp_svm, self.acc_svm, self.auc_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`6.LDA分类` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myLDA(self,data,n):\n",
    "\n",
    "    kf = KFold(n_splits = 5,shuffle = True,random_state = None)\n",
    "    for train_id, test_id in kf.split(data):\n",
    "        # print(\"TRAIN:\", train_id, \"TEST:\", test_id)\n",
    "        x_train =np.array([data[\"身高\"].iloc[train_id],data[\"体重\"].iloc[train_id],\n",
    "                data[\"50米成绩\"].iloc[train_id],data[\"肺活量\"].iloc[train_id]])\n",
    "        x_test =np.array([data[\"身高\"].iloc[test_id],data[\"体重\"].iloc[test_id],\n",
    "                data[\"50米成绩\"].iloc[test_id],data[\"肺活量\"].iloc[test_id]])\n",
    "        y_train, y_test =np.array(data[\"性别男1女0\"].iloc[train_id]),np.array(data[\"性别男1女0\"].iloc[test_id])\n",
    "        x_train=np.transpose(x_train);x_test=np.transpose(x_test)\n",
    "        print(len(x_train), len(x_test), len(y_train), len(y_test))\n",
    "        lda = LDA(n_components=n)\n",
    "        lda.fit(x_train, y_train)\n",
    "        lda_pred=lda.predict(x_test)\n",
    "        se,sp,acc,auc = eval(lda_pred,y_test)\n",
    "        self.se_lda.append(se);self.sp_lda.append(sp);self.acc_lda.append(acc);self.auc_lda.append(auc)\n",
    "    return self.se_lda, self.sp_lda, self.acc_lda, self.auc_lda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5.可视化`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vitualize(clf):\n",
    "    return\n",
    "\n",
    "vitualize(clf)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7f719f333d963901e84c1341a59b52adbec260a901cd43e726cf48e69a71650"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('covid')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
